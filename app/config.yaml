models_dir: /models
models_family: llama_gptq
setup_params:
  repo_id: TheBloke/Llama-2-13B-GPTQ
  filename: model.safetensors
model_params:
  group_size: 128
  wbits: 4
  cuda_visible_devices: "0"
  device: "cuda:0"
