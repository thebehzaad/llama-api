models_dir: /models/llama_13b_hf_gptq
models_family: llama_gptq

setup_params:
  repo_id: TheBloke/Llama-2-13B-GPTQ
  filename: model.safetensors
model_params:
  group_size: 128
  wbits: 4
  cuda_visible_devices: "0"
  device: "cuda:0"
